{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a88f91d",
   "metadata": {},
   "source": [
    "# Functions, tools and agents\n",
    "\n",
    "We're going to improve two of the demos in this tutorial with the use of what you've just learnt in this section:\n",
    "\n",
    "- Structured outputs\n",
    "- Tool calls\n",
    "\n",
    "In the last section, we built a basic RAG bot with a search using embeddings. In the data set, there is a price field. \n",
    "\n",
    "Embedding models aren't designed for filtering, especially since numbers are all treated with strong similarity.\n",
    "\n",
    "Let's improve the search by requesting that the AI return some specific price filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import utils\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you change the environment variables, you need to restart the kernel\n",
    "base_url = utils.get_base_url()\n",
    "api_key = utils.get_api_key()\n",
    "\n",
    "if utils.MODE == \"github\":\n",
    "    model = \"openai/gpt-4.1-nano\"  # A fast, small model\n",
    "elif utils.MODE == \"ollama\":\n",
    "    model = \"llama3.1\"  # llama and ollama are not related. It's a coincidence\n",
    "\n",
    "# OpenAI client is a class. The old API used to use globals. Sometimes you might see code snippets for the old API. \n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f7ae0",
   "metadata": {},
   "source": [
    "# Defining tools\n",
    "\n",
    "As with most things, OpenAI did this first and most other models copied. So even if you're not using OpenAI models, see [OpenAI Spec](https://platform.openai.com/docs/guides/function-calling?api-mode=responses#defining-functions) for usage.\n",
    "\n",
    "Tools have:\n",
    " - A type (e.g. `function`)\n",
    " - A name which should be snake-case\n",
    " - A description. This is important, especially if there are multiple tools. Treat it like a prompt.\n",
    " - Parameters\n",
    " - Whether the function is \"strict\" i.e. function calls reliably adhere to the function schema, instead of being best effort. We recommend always enabling strict mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518dd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tool for filtering prices within a range. Is not required. User could say \"less than $10\", or \"between $5 and $10\".\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"price_filter\",\n",
    "            \"description\": \"Filter prices within a range.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"min_price\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Minimum price to filter.\",\n",
    "                    },\n",
    "                    \"max_price\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Maximum price to filter.\",\n",
    "                    },\n",
    "                },\n",
    "                # Both parameters are optional. But this is how you could specify them as required.\n",
    "                # \"required\": [\"min_price\", \"max_price\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb09698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try that with a prompt\n",
    "\n",
    "def query_with_filter(query):\n",
    "    response =client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can find products.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "\n",
    "\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        if tool_call.function.name == \"price_filter\":\n",
    "            return tool_call.function.arguments\n",
    "\n",
    "print(query_with_filter(\"Find me a product that costs between $5 and $10.\"))\n",
    "print(query_with_filter(\"I'm looking for a hat that's less than $10.\"))\n",
    "print(query_with_filter(\"Birthday scarf. At least $24.99.\"))\n",
    "print(query_with_filter(\"Mothers day gift ideas for 20-30 bucks.\"))\n",
    "print(query_with_filter(\"Find me a product that costs loads-a-money.\"))  # This one is a big ambiguous, but lets see what it does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469e7e9",
   "metadata": {},
   "source": [
    "## Task: \n",
    "\n",
    "1. Experiment with some different questions and see what the filters look like.\n",
    "1. Modify the function below to filter out the dataframe by price before sorting it by similarity\n",
    "1. Update the `rag_chat` function and complete the two TODO items\n",
    "1. Test the discussion with various searches. Start with the suggestions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the tool call responses\n",
    "from typing import Optional\n",
    "import utils\n",
    "from utils.embeddings import get_embedding_client, cosine_similarity, get_embedding, load_clothing_data  # See utils/embeddings.py for the cosine similarity function (its not complicated)\n",
    "\n",
    "embedding_client, dimensions, embedding_model = get_embedding_client()\n",
    "\n",
    "def search_df(df, product_description, n=3, min_price : Optional[float] = None, max_price: Optional[float] = None):\n",
    "    embedding = get_embedding(embedding_client, model=embedding_model, dimensions=dimensions, input=product_description)\n",
    "    df['similarities'] = df.embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    # TODO : filter the dataframe by price\n",
    "\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "    return res\n",
    "\n",
    "data = load_clothing_data(embedding_model)\n",
    "\n",
    "\n",
    "def rag_chat(query, n=3):\n",
    "    # TODO: Get the filter parameters for `query`\n",
    "\n",
    "    # TODO: Update the search function to filter by price\n",
    "    matches = search_df(data, query, n=n)\n",
    "    \n",
    "    # Merge this into a prompt\n",
    "    # TODO : Find your \"winning prompt from the last exercise\"\n",
    "    system_prompt = f\"\"\"\n",
    "    The user has asked about a product, you are a helpful assistant that can give suggestions about products we have. \n",
    "\n",
    "    The matching products are:\n",
    "    \"\"\"\n",
    "\n",
    "    for match in matches.iterrows():\n",
    "        match = match[1]\n",
    "        system_prompt += f\"\"\"\n",
    "        Name: {match['name']}\n",
    "        Description: {match.description}\n",
    "        URL: https://www.superpythonshop.com/products/{match.id}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # Step 2: Call the model with the prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # Step 3: Return the response\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(rag_chat(\"I need a warm hat for winter less than $20\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6a0ac",
   "metadata": {},
   "source": [
    "# Elemental Clash AI ✨✨✨\n",
    "\n",
    "I've taken 7 photos of playing cards on a table and we're going to get the AI to work out which player wins in our game **Elemental Clash**.\n",
    "\n",
    "![Card picture](data/cards/IMG_9059.jpg)\n",
    "\n",
    "If you want to add your own photos using a phone, please do!\n",
    "\n",
    "First, lets define the data structure for the cards so we can use Structured Outputs to get the cards played as PyDantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82835f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from enum import StrEnum # Python 3.11 + otherwise use (str, Enum) as base class\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from typing import cast\n",
    "\n",
    "\n",
    "class CardSuit(str, Enum):\n",
    "    hearts = \"hearts\"\n",
    "    diamonds = \"diamonds\"\n",
    "    clubs = \"clubs\"\n",
    "    spades = \"spades\"\n",
    "\n",
    "\n",
    "class CardValue(str, Enum):\n",
    "    two = \"2\"\n",
    "    three = \"3\"\n",
    "    four = \"4\"\n",
    "    five = \"5\"\n",
    "    six = \"6\"\n",
    "    seven = \"7\"\n",
    "    eight = \"8\"\n",
    "    nine = \"9\"\n",
    "    ten = \"10\"\n",
    "    jack = \"J\"\n",
    "    queen = \"Q\"\n",
    "    king = \"K\"\n",
    "    ace = \"A\"\n",
    "\n",
    "SUIT_GLYPHS = {\n",
    "    CardSuit.hearts: \"♥\",\n",
    "    CardSuit.diamonds: \"♦\",\n",
    "    CardSuit.clubs: \"♣\",\n",
    "    CardSuit.spades: \"♠\",\n",
    "}\n",
    "\n",
    "class PlayedCard(BaseModel):\n",
    "    suit: CardSuit\n",
    "    value: CardValue\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.value.name} of {SUIT_GLYPHS[self.suit]}\"\n",
    "\n",
    "\n",
    "class PlayedCards(BaseModel):\n",
    "    cards: list[PlayedCard]\n",
    "\n",
    "\n",
    "def parse_played_cards(message) -> PlayedCards:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"What cards were played.\"},\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "        ],\n",
    "        response_format=PlayedCards,\n",
    "    )\n",
    "\n",
    "\n",
    "    message = completion.choices[0].message\n",
    "    if message.refusal:\n",
    "        print(message.refusal)\n",
    "        raise ValueError(\"Could not parse the message.\")\n",
    "    else:\n",
    "        return cast(PlayedCards, message.parsed)\n",
    "\n",
    "parse_played_cards(\"John played the ace of spades. Sarita played the queen of hearts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a208b",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Next, let's combine this with a function called `determine_player_programmatically` which will evaluate (using Python, not AI) which player wins a turn.\n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Add player's name to the structured output by adding it as an attribute to `PlayedCard`\n",
    "1. Verify it works\n",
    "1. Call `determine_winner_programmatically` with a dictionary where `key` is player name and `value` is the card.\n",
    "1. The value needs to be in the format of `[value] of [suit]` e.g. `\"2 of spades\"` or `\"K of hearts\"`\n",
    "1. Print the winning player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75219b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.game import determine_winner_programmatically\n",
    "\n",
    "sample_query = \"John played the ace of spades. Sarita played the queen of hearts.\"\n",
    "\n",
    "# TODO: implement as per instructions\n",
    "winner = ...\n",
    "\n",
    "assert winner == \"John\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d255c",
   "metadata": {},
   "source": [
    "# Adding a visual model\n",
    "\n",
    "To recognise what cards are played on the table, we can use a visual, or \"multi-modal\" model.\n",
    "\n",
    "The GPT-4o series is one of the most popular multi-modal models and it also supports structured outputs.\n",
    "\n",
    "For local development, `gemma3`, `phi4` and `llama4:scout` are the best options (this week!).\n",
    "\n",
    "Importantly, images should be **small** in file size and dimensions. PNG, JPEG and WEBP are all supported formats. I recommend using JPEG with a max dimensions of 1024x1024. Crop and compress the image to be >300kB.\n",
    "\n",
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dde678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "image_model = \"openai/gpt-4.1-mini\" if utils.MODE == \"github\" else \"gemma3:4b\"\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Image url can either be the URL of a web image, or a base64 encoded image\n",
    "\n",
    "base64_image = encode_image(\"data/cards/IMG_9059.jpg\")\n",
    "image_url = f\"data:image/jpeg;base64,{base64_image}\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=image_model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\", \n",
    "                   \"text\": \"What cards are on the table\" },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": image_url, \"type\": \"image_url\"}\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.content\n",
    "display(Markdown(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4e016",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "1. Use the `parse_played_cards` or the structured output parameter to this code and see if you can get a list of cards as a Python object.\n",
    "1. Write a program to determine the winner from any photo in `data/cards` by combining everything you've learned in this module. Since we don't know the player name in the image, just assign them a number and say what their card was.\n",
    "\n",
    "NB: The smaller, local models might not be able to accurately get _all_ of the cards on the table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25307734",
   "metadata": {},
   "source": [
    "# Agentic Frameworks\n",
    "\n",
    "Everything you've done so far in this tutorial has led up to \"agents\"\n",
    "\n",
    "Agentic programming is a way of connecting tasks, whether they be AI-driven, programmatic, or human-driven.\n",
    "\n",
    "For our card game, the flow is:\n",
    "\n",
    "- Someone deals each player 5 cards\n",
    "- The players choose a card and place it face down\n",
    "- The cards are turned over\n",
    "- The cards are analysed (we just automated that part)\n",
    "- The winner is decided\n",
    "\n",
    "Lets build a deck of cards in Python using a generator to deal from a deck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.game import deal, determine_winner_programmatically\n",
    "\n",
    "deck = deal()  # Generates next card\n",
    "\n",
    "player1_hand = [next(deck) for _ in range(5)]\n",
    "player2_hand = [next(deck) for _ in range(5)]\n",
    "player3_hand = [next(deck) for _ in range(5)]\n",
    "\n",
    "scores = {\n",
    "    \"Player 1\": 0,\n",
    "    \"Player 2\": 0,\n",
    "    \"Player 3\": 0,\n",
    "}\n",
    "\n",
    "for turn in range(5):\n",
    "    print(\"Player 1 played\", player1_hand[turn])\n",
    "    print(\"Player 2 played\", player2_hand[turn])\n",
    "    print(\"Player 3 played\", player3_hand[turn])\n",
    "\n",
    "    # Determine winner\n",
    "    winner = determine_winner_programmatically(\n",
    "        {\n",
    "            \"Player 1\": player1_hand[turn], \n",
    "            \"Player 2\": player2_hand[turn], \n",
    "            \"Player 3\": player3_hand[turn]\n",
    "        }\n",
    "    )\n",
    "    print(f\"Winner: {winner}\\n\")\n",
    "    # Update scores\n",
    "    scores[winner] += 1\n",
    "\n",
    "print(\"Final Scores:\")\n",
    "for player, score in scores.items():\n",
    "    print(f\"{player}: {score} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext, BinaryContent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from openai import AsyncOpenAI\n",
    "from utils.game import RULES\n",
    "\n",
    "# Pydantic AI wants async clients by default\n",
    "pai_model = OpenAIModel(\n",
    "    model_name=model,\n",
    "    provider=OpenAIProvider(openai_client=AsyncOpenAI(base_url=base_url, api_key=api_key)),\n",
    ")\n",
    "\n",
    "cardplaying_agent = Agent(\n",
    "    pai_model,\n",
    "    deps_type=PlayedCards,\n",
    "    output_type=str,\n",
    "    system_prompt=f\"You are a card game assistant. The rules of the game are {RULES}. You determine the winner using determine_winner. Give an interesting commentary of which cards were played. Give the cards their elemental names\",\n",
    ")\n",
    "\n",
    "@cardplaying_agent.tool\n",
    "async def determine_winner(\n",
    "    context: RunContext,\n",
    "    cards: PlayedCards,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Determine the winner of a card game based on the played cards.\n",
    "    \"\"\"\n",
    "    table = {f\"Player {i}\": repr(card) for i, card in enumerate(cards.cards, start=1)}\n",
    "    winner = determine_winner_programmatically(table)\n",
    "    return f\"The winner is {winner} who played {table[winner]}.\"\n",
    "\n",
    "with open('data/cards/IMG_9059.jpg', 'rb') as image_file:\n",
    "    data = image_file.read()\n",
    "table_photo = BinaryContent(data, media_type=\"image/jpeg\")\n",
    "\n",
    "result = await cardplaying_agent.run('Who wins this turn', [\n",
    "    \n",
    "]))\n",
    "print(result.output)\n",
    "print(result.usage())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
