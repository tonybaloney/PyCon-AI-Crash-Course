{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a88f91d",
   "metadata": {},
   "source": [
    "# Functions, tools and agents\n",
    "\n",
    "We're going to improve two of the demos in this tutorial with the use of what you've just learnt in this section:\n",
    "\n",
    "- Structured outputs\n",
    "- Tool calls\n",
    "\n",
    "In the last section, we built a basic RAG bot with a search using embeddings. In the data set, there is a price field. \n",
    "\n",
    "Embedding models aren't designed for filtering, especially since numbers are all treated with strong similarity.\n",
    "\n",
    "Let's improve the search by requesting that the AI return some specific price filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c6255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import utils\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you change the environment variables, you need to restart the kernel\n",
    "base_url = utils.get_base_url()\n",
    "api_key = utils.get_api_key()\n",
    "\n",
    "if utils.MODE == \"github\":\n",
    "    model = \"openai/gpt-4.1-nano\"  # A fast, small model\n",
    "elif utils.MODE == \"ollama\":\n",
    "    model = \"llama3.1\"  # llama and ollama are not related. It's a coincidence\n",
    "\n",
    "# OpenAI client is a class. The old API used to use globals. Sometimes you might see code snippets for the old API. \n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f7ae0",
   "metadata": {},
   "source": [
    "# Defining tools\n",
    "\n",
    "As with most things, OpenAI did this first and most other models copied. So even if you're not using OpenAI models, see [OpenAI Spec](https://platform.openai.com/docs/guides/function-calling?api-mode=responses#defining-functions) for usage.\n",
    "\n",
    "Tools have:\n",
    " - A type (e.g. `function`)\n",
    " - A name which should be snake-case\n",
    " - A description. This is important, especially if there are multiple tools. Treat it like a prompt.\n",
    " - Parameters\n",
    " - Whether the function is \"strict\" i.e. function calls reliably adhere to the function schema, instead of being best effort. We recommend always enabling strict mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518dd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tool for filtering prices within a range. Is not required. User could say \"less than $10\", or \"between $5 and $10\".\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"price_filter\",\n",
    "            \"description\": \"Filter prices within a range.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"min_price\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Minimum price to filter.\",\n",
    "                    },\n",
    "                    \"max_price\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Maximum price to filter.\",\n",
    "                    },\n",
    "                },\n",
    "                # Both parameters are optional. But this is how you could specify them as required.\n",
    "                # \"required\": [\"min_price\", \"max_price\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb09698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"min_price\":5,\"max_price\":10}\n",
      "{\"max_price\":10}\n",
      "{\"min_price\": 24.99}\n",
      "{\"max_price\": 30}\n",
      "{\"max_price\":100000}\n"
     ]
    }
   ],
   "source": [
    "# Let's try that with a prompt\n",
    "\n",
    "def query_with_filter(query):\n",
    "    response =client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can find products.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "\n",
    "\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        if tool_call.function.name == \"price_filter\":\n",
    "            return tool_call.function.arguments\n",
    "\n",
    "print(query_with_filter(\"Find me a product that costs between $5 and $10.\"))\n",
    "print(query_with_filter(\"I'm looking for a hat that's less than $10.\"))\n",
    "print(query_with_filter(\"Birthday scarf. At least $24.99.\"))\n",
    "print(query_with_filter(\"Mothers day gift ideas for 20-30 bucks.\"))\n",
    "print(query_with_filter(\"Find me a product that costs loads-a-money.\"))  # This one is a big ambiguous, but lets see what it does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469e7e9",
   "metadata": {},
   "source": [
    "## Task: \n",
    "\n",
    "1. Experiment with some different questions and see what the filters look like.\n",
    "1. Modify the function below to filter out the dataframe by price before sorting it by similarity\n",
    "1. Update the `rag_chat` function and complete the two TODO items\n",
    "1. Test the discussion with various searches. Start with the suggestions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd19e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on your requirements, I recommend the Blizzard White Beanie. It is designed to keep you warm during the coldest days and is likely to be priced under $20. You can find more details and purchase it here: [Blizzard White Beanie](https://www.superpythonshop.com/products/105)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the tool call responses\n",
    "from typing import Optional\n",
    "import utils\n",
    "from utils.embeddings import get_embedding_client, cosine_similarity, get_embedding, load_clothing_data  # See utils/embeddings.py for the cosine similarity function (its not complicated)\n",
    "\n",
    "embedding_client, dimensions, embedding_model = get_embedding_client()\n",
    "\n",
    "def search_df(df, product_description, n=3, min_price : Optional[float] = None, max_price: Optional[float] = None):\n",
    "    embedding = get_embedding(embedding_client, model=embedding_model, dimensions=dimensions, input=product_description)\n",
    "    df['similarities'] = df.embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    # TODO : filter the dataframe by price\n",
    "\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "    return res\n",
    "\n",
    "data = load_clothing_data(embedding_model)\n",
    "\n",
    "\n",
    "def rag_chat(query, n=3):\n",
    "    # TODO: Get the filter parameters for `query`\n",
    "\n",
    "    # TODO: Update the search function to filter by price\n",
    "    matches = search_df(data, query, n=n)\n",
    "    \n",
    "    # Merge this into a prompt\n",
    "    # TODO : Find your \"winning prompt from the last exercise\"\n",
    "    system_prompt = f\"\"\"\n",
    "    The user has asked about a product, you are a helpful assistant that can give suggestions about products we have. \n",
    "\n",
    "    The matching products are:\n",
    "    \"\"\"\n",
    "\n",
    "    for match in matches.iterrows():\n",
    "        match = match[1]\n",
    "        system_prompt += f\"\"\"\n",
    "        Name: {match['name']}\n",
    "        Description: {match.description}\n",
    "        URL: https://www.superpythonshop.com/products/{match.id}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # Step 2: Call the model with the prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # Step 3: Return the response\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(rag_chat(\"I need a warm hat for winter less than $20\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6a0ac",
   "metadata": {},
   "source": [
    "# Elemental Clash AI ✨✨✨\n",
    "\n",
    "I've taken 7 photos of playing cards on a table and we're going to get the AI to work out which player wins in our game **Elemental Clash**.\n",
    "\n",
    "![Card picture](data/cards/IMG_9059.jpg)\n",
    "\n",
    "If you want to add your own photos using a phone, please do!\n",
    "\n",
    "First, lets define the data structure for the cards so we can use Structured Outputs to get the cards played as PyDantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b82835f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cards=[ace of ♠, queen of ♥]\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CardSuit(str, Enum):\n",
    "    hearts = \"hearts\"\n",
    "    diamonds = \"diamonds\"\n",
    "    clubs = \"clubs\"\n",
    "    spades = \"spades\"\n",
    "\n",
    "\n",
    "class CardValue(str, Enum):\n",
    "    two = \"2\"\n",
    "    three = \"3\"\n",
    "    four = \"4\"\n",
    "    five = \"5\"\n",
    "    six = \"6\"\n",
    "    seven = \"7\"\n",
    "    eight = \"8\"\n",
    "    nine = \"9\"\n",
    "    ten = \"10\"\n",
    "    jack = \"J\"\n",
    "    queen = \"Q\"\n",
    "    king = \"K\"\n",
    "    ace = \"A\"\n",
    "\n",
    "SUIT_GLYPHS = {\n",
    "    CardSuit.hearts: \"♥\",\n",
    "    CardSuit.diamonds: \"♦\",\n",
    "    CardSuit.clubs: \"♣\",\n",
    "    CardSuit.spades: \"♠\",\n",
    "}\n",
    "\n",
    "class Card(BaseModel):\n",
    "    suit: CardSuit\n",
    "    value: CardValue\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.value.name} of {SUIT_GLYPHS[self.suit]}\"\n",
    "\n",
    "\n",
    "class PlayedCards(BaseModel):\n",
    "    cards: list[Card]\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"John played the ace of spades. Sarita played the queen of hearts.\"},\n",
    "    ],\n",
    "    response_format=PlayedCards,\n",
    ")\n",
    "\n",
    "\n",
    "message = completion.choices[0].message\n",
    "if message.refusal:\n",
    "    print(message.refusal)\n",
    "else:\n",
    "    event = message.parsed\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
